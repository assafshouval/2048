{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":66632,"databundleVersionId":7388776,"sourceType":"competition"}],"dockerImageVersionId":30626,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install h5py","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-01-10T16:17:19.499429Z","iopub.execute_input":"2024-01-10T16:17:19.499862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import h5py\nimport os\ntrain_data = r'train.h5'\ndb = h5py.File(train_data, 'r')\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-01-10T16:17:19.499429Z","iopub.execute_input":"2024-01-10T16:17:19.499862Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Requirement already satisfied: h5py in /opt/conda/lib/python3.10/site-packages (3.9.0)\nRequirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.10/site-packages (from h5py) (1.24.3)\n","output_type":"stream"}]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import layers, models\n\ndef create_character_cnn(input_shape, num_classes):\n    model = models.Sequential()\n    \n    # Convolutional layers\n    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n    model.add(layers.MaxPooling2D((2, 2)))\n    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n    model.add(layers.MaxPooling2D((2, 2)))\n    model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n    model.add(layers.MaxPooling2D((2, 2)))\n    \n    # Flatten layer to transition from convolutional to dense layers\n    model.add(layers.Flatten())\n    \n    # Dense layers for classification\n    model.add(layers.Dense(128, activation='relu'))\n    model.add(layers.Dropout(0.5))  # Optional dropout layer for regularization\n    model.add(layers.Dense(num_classes, activation='softmax'))\n    \n    # Compile the model\n    model.compile(optimizer='adam',\n                  loss='categorical_crossentropy',\n                  metrics=['accuracy'])\n    \n    return model\n\nchar_a_model = create_character_cnn(input_shape=(64, 64, 3), num_classes=7)\n\n# Display model summaries\nchar_a_model.summary()\n","metadata":{"execution":{"iopub.status.busy":"2024-01-13T16:21:07.590703Z","iopub.execute_input":"2024-01-13T16:21:07.591214Z","iopub.status.idle":"2024-01-13T16:21:07.748716Z","shell.execute_reply.started":"2024-01-13T16:21:07.591179Z","shell.execute_reply":"2024-01-13T16:21:07.747432Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Model: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n conv2d (Conv2D)             (None, 62, 62, 32)        896       \n                                                                 \n max_pooling2d (MaxPooling2  (None, 31, 31, 32)        0         \n D)                                                              \n                                                                 \n conv2d_1 (Conv2D)           (None, 29, 29, 64)        18496     \n                                                                 \n max_pooling2d_1 (MaxPoolin  (None, 14, 14, 64)        0         \n g2D)                                                            \n                                                                 \n conv2d_2 (Conv2D)           (None, 12, 12, 128)       73856     \n                                                                 \n max_pooling2d_2 (MaxPoolin  (None, 6, 6, 128)         0         \n g2D)                                                            \n                                                                 \n flatten (Flatten)           (None, 4608)              0         \n                                                                 \n dense (Dense)               (None, 128)               589952    \n                                                                 \n dropout (Dropout)           (None, 128)               0         \n                                                                 \n dense_1 (Dense)             (None, 7)                 903       \n                                                                 \n=================================================================\nTotal params: 684103 (2.61 MB)\nTrainable params: 684103 (2.61 MB)\nNon-trainable params: 0 (0.00 Byte)\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"\n\nim_names = list(db['data'].keys())\nx_train_masked_a = []\ny_train_a = []\n#mask images before feeding:\nfor name in im_names[:100]:\n    img = db['data'][name][:]\n    font = db['data'][name].attrs['font']\n    txt = db['data'][name].attrs['txt']\n    charBB = db['data'][name].attrs['charBB']\n    wordBB = db['data'][name].attrs['wordBB']\n    for w in range(wordBB.shape[-1]):\n        cropped = crop_image(img, wordBB[:, :, w])\n        if cropped is not None and np.any(cropped.size) and np.all(cropped.shape):\n            x_train_masked_a.append(cropped)\n            y_train_masked_a.append(font[w])\nprint('batch size = ', len(x_train_masked_a), len(y_train_masked_a))\n\n","metadata":{"execution":{"iopub.status.busy":"2024-01-13T16:07:41.926341Z","iopub.execute_input":"2024-01-13T16:07:41.927026Z","iopub.status.idle":"2024-01-13T16:07:43.051821Z","shell.execute_reply.started":"2024-01-13T16:07:41.926967Z","shell.execute_reply":"2024-01-13T16:07:43.050108Z"},"trusted":true},"execution_count":1,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mutilities\u001b[39;00m\n\u001b[1;32m      3\u001b[0m im_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(db[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[1;32m      4\u001b[0m x_train_masked_a \u001b[38;5;241m=\u001b[39m []\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'utilities'"],"ename":"ModuleNotFoundError","evalue":"No module named 'utilities'","output_type":"error"}]},{"cell_type":"code","source":"# Example training with masked images\nchar_a_model.fit(x_train_masked_a, y_train_a, epochs=num_epochs, batch_size=batch_size)\n\n# Example prediction with masked images\npredictions_a = char_a_model.predict(x_test_masked_a)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This is how to submit","metadata":{}},{"cell_type":"code","source":"# fonts_prediction_ids: [3,3,3,0,0,2,2 ...]\ndef submit_predictions(fonts_prediction_ids):\n    \n    df = pd.DataFrame(fonts_prediction_ids)\n    df['Index'] = range(len(df))\n    new_df = pd.DataFrame({'ind': df['Index'], 'font': fonts_prediction_ids}) \n    new_df.to_csv(_DIRNAME_WORKING_ + \"submission.csv\", index=False\nmap_dict = {0: 'Flower Rose Brush',\n            1: 'Skylark',\n            2: 'Sweet Puppy',\n            3: 'Ubuntu Mono',\n            4: 'VertigoFLF',\n            5: 'Wanted M54',\n            6: 'always forever'}\n\nsub = pd.read_csv(\"sample_submission.csv\")\nsub['font'] = sub['font'].map({v: k for k, v in map_dict.items()})\nnew_df =pd.DataFrame({'ind': sub.index, 'font': sub['font'].values})\nnew_df.to_csv(\"new_sub.csv\")\n\n\n\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}